{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jobaerislam/lung-colon?scriptVersionId=251083060\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"628d7eac","metadata":{"execution":{"iopub.execute_input":"2025-07-17T20:32:50.778204Z","iopub.status.busy":"2025-07-17T20:32:50.777876Z","iopub.status.idle":"2025-07-17T20:33:03.023135Z","shell.execute_reply":"2025-07-17T20:33:03.02218Z"},"papermill":{"duration":12.252065,"end_time":"2025-07-17T20:33:03.024805","exception":false,"start_time":"2025-07-17T20:32:50.77274","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import DataLoader, random_split"]},{"cell_type":"code","execution_count":2,"id":"33590934","metadata":{"execution":{"iopub.execute_input":"2025-07-17T20:33:03.031373Z","iopub.status.busy":"2025-07-17T20:33:03.030952Z","iopub.status.idle":"2025-07-17T20:33:19.086734Z","shell.execute_reply":"2025-07-17T20:33:19.085441Z"},"papermill":{"duration":16.060964,"end_time":"2025-07-17T20:33:19.088376","exception":false,"start_time":"2025-07-17T20:33:03.027412","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Classes: ['colon_image_sets', 'lung_image_sets']\n"]}],"source":["\n","# ----- Step 1: Data Transform and Loading -----\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","])\n","\n","# Replace the path below with your dataset location if needed\n","DATA_ROOT = '/kaggle/input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set'\n","full_dataset = datasets.ImageFolder(root=DATA_ROOT, transform=transform)\n","print(\"Classes:\", full_dataset.classes)"]},{"cell_type":"code","execution_count":3,"id":"b83a2b14","metadata":{"execution":{"iopub.execute_input":"2025-07-17T20:33:19.09545Z","iopub.status.busy":"2025-07-17T20:33:19.094791Z","iopub.status.idle":"2025-07-17T20:33:19.133736Z","shell.execute_reply":"2025-07-17T20:33:19.132587Z"},"papermill":{"duration":0.044969,"end_time":"2025-07-17T20:33:19.136002","exception":false,"start_time":"2025-07-17T20:33:19.091033","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Train size: 17500, Val size: 3750, Test size: 3750\n"]}],"source":["# ----- Step 2: Dataset Split: 70/15/15 -----\n","total_size = len(full_dataset)\n","train_size = int(0.7 * total_size)\n","val_size = int(0.15 * total_size)\n","test_size = total_size - train_size - val_size\n","\n","train_dataset, val_dataset, test_dataset = random_split(\n","    full_dataset, [train_size, val_size, test_size],\n","    generator=torch.Generator().manual_seed(42)\n",")\n","\n","print(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}, Test size: {len(test_dataset)}\")\n"]},{"cell_type":"code","execution_count":4,"id":"b464e44b","metadata":{"execution":{"iopub.execute_input":"2025-07-17T20:33:19.142825Z","iopub.status.busy":"2025-07-17T20:33:19.142494Z","iopub.status.idle":"2025-07-17T20:33:19.150721Z","shell.execute_reply":"2025-07-17T20:33:19.149481Z"},"papermill":{"duration":0.013607,"end_time":"2025-07-17T20:33:19.152545","exception":false,"start_time":"2025-07-17T20:33:19.138938","status":"completed"},"tags":[]},"outputs":[],"source":["# ----- Step 3: Train dataset split for FL clients (3 clients) -----\n","client_split = [train_size // 3, train_size // 3, train_size - 2 * (train_size // 3)]\n","client_datasets = random_split(\n","    train_dataset, client_split,\n","    generator=torch.Generator().manual_seed(42)\n",")\n","client_loaders = [DataLoader(ds, batch_size=16, shuffle=True, num_workers=2) for ds in client_datasets]\n","\n","# ----- Step 4: Val/Test Loaders -----\n","val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)"]},{"cell_type":"code","execution_count":5,"id":"59c52376","metadata":{"execution":{"iopub.execute_input":"2025-07-17T20:33:19.159032Z","iopub.status.busy":"2025-07-17T20:33:19.15867Z","iopub.status.idle":"2025-07-17T20:33:19.165373Z","shell.execute_reply":"2025-07-17T20:33:19.164442Z"},"papermill":{"duration":0.011702,"end_time":"2025-07-17T20:33:19.166915","exception":false,"start_time":"2025-07-17T20:33:19.155213","status":"completed"},"tags":[]},"outputs":[],"source":["# ----- Step 5: Define MobileNetV2 model -----\n","def create_model():\n","    model = models.mobilenet_v2(pretrained=True)\n","    model.classifier[1] = nn.Linear(model.last_channel, 5)  # Adjust class count if needed\n","    return model\n","\n","# ----- Step 6: Local training function -----\n","def train_local(model, dataloader, epochs=1, lr=1e-3, device='cpu'):\n","    model.train()\n","    model.to(device)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    for epoch in range(epochs):\n","        for images, labels in dataloader:\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","    return model.state_dict()"]},{"cell_type":"code","execution_count":6,"id":"6f7488cd","metadata":{"execution":{"iopub.execute_input":"2025-07-17T20:33:19.172742Z","iopub.status.busy":"2025-07-17T20:33:19.172381Z","iopub.status.idle":"2025-07-17T20:33:19.177419Z","shell.execute_reply":"2025-07-17T20:33:19.176539Z"},"papermill":{"duration":0.009644,"end_time":"2025-07-17T20:33:19.178928","exception":false,"start_time":"2025-07-17T20:33:19.169284","status":"completed"},"tags":[]},"outputs":[],"source":["# ----- Step 7: Federated averaging (FedAvg) -----\n","def average_weights(weights_list):\n","    avg_weights = {}\n","    for key in weights_list[0].keys():\n","        avg_weights[key] = torch.stack([w[key].float() for w in weights_list], 0).mean(0)\n","    return avg_weights\n"]},{"cell_type":"code","execution_count":7,"id":"110d7558","metadata":{"execution":{"iopub.execute_input":"2025-07-17T20:33:19.184915Z","iopub.status.busy":"2025-07-17T20:33:19.184617Z","iopub.status.idle":"2025-07-17T20:33:19.190825Z","shell.execute_reply":"2025-07-17T20:33:19.189786Z"},"papermill":{"duration":0.01094,"end_time":"2025-07-17T20:33:19.192375","exception":false,"start_time":"2025-07-17T20:33:19.181435","status":"completed"},"tags":[]},"outputs":[],"source":["\n","# ----- Step 8: Evaluation function -----\n","def evaluate(model, dataloader, device='cpu'):\n","    model.eval()\n","    model.to(device)\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels in dataloader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    return correct / total"]},{"cell_type":"code","execution_count":8,"id":"1198df25","metadata":{"execution":{"iopub.execute_input":"2025-07-17T20:33:19.200034Z","iopub.status.busy":"2025-07-17T20:33:19.199745Z","iopub.status.idle":"2025-07-17T22:44:31.138858Z","shell.execute_reply":"2025-07-17T22:44:31.137062Z"},"papermill":{"duration":7871.951307,"end_time":"2025-07-17T22:44:31.146459","exception":false,"start_time":"2025-07-17T20:33:19.195152","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cpu\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n","100%|██████████| 13.6M/13.6M [00:00<00:00, 107MB/s] \n"]},{"name":"stdout","output_type":"stream","text":["--- Round 1 ---\n","Training client 1 locally...\n","Training client 2 locally...\n","Training client 3 locally...\n","Round 1 completed.\n","Validation Accuracy: 0.9587\n","Test Accuracy:       0.9600\n","\n","--- Round 2 ---\n","Training client 1 locally...\n","Training client 2 locally...\n","Training client 3 locally...\n","Round 2 completed.\n","Validation Accuracy: 0.9923\n","Test Accuracy:       0.9885\n","\n","--- Round 3 ---\n","Training client 1 locally...\n","Training client 2 locally...\n","Training client 3 locally...\n","Round 3 completed.\n","Validation Accuracy: 0.9384\n","Test Accuracy:       0.9408\n","\n","--- Round 4 ---\n","Training client 1 locally...\n","Training client 2 locally...\n","Training client 3 locally...\n","Round 4 completed.\n","Validation Accuracy: 0.9856\n","Test Accuracy:       0.9872\n","\n","--- Round 5 ---\n","Training client 1 locally...\n","Training client 2 locally...\n","Training client 3 locally...\n","Round 5 completed.\n","Validation Accuracy: 0.9989\n","Test Accuracy:       0.9997\n","\n"]}],"source":["\n","# ----- Step 9: Federated training loop -----\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","global_model = create_model()\n","global_model.to(device)\n","\n","NUM_ROUNDS = 5\n","EPOCHS_PER_CLIENT = 1\n","\n","for round_num in range(1, NUM_ROUNDS + 1):\n","    print(f\"--- Round {round_num} ---\")\n","    local_weights = []\n","\n","    for i, dataloader in enumerate(client_loaders):\n","        print(f\"Training client {i+1} locally...\")\n","        local_model = create_model()\n","        local_model.load_state_dict(global_model.state_dict())\n","        local_weights.append(\n","            train_local(local_model, dataloader, epochs=EPOCHS_PER_CLIENT, device=device)\n","        )\n","\n","    # Federated averaging of all client models\n","    averaged_weights = average_weights(local_weights)\n","    global_model.load_state_dict(averaged_weights)\n","\n","    # Evaluate on validation and test sets\n","    val_acc = evaluate(global_model, val_loader, device=device)\n","    test_acc = evaluate(global_model, test_loader, device=device)\n","\n","    print(f\"Round {round_num} completed.\")\n","    print(f\"Validation Accuracy: {val_acc:.4f}\")\n","    print(f\"Test Accuracy:       {test_acc:.4f}\\n\")\n","\n","# ----- Step 10: Save the global model -----\n","torch.save(global_model.state_dict(), 'federated_mobilenetv2.pth')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":601280,"sourceId":1079953,"sourceType":"datasetVersion"}],"dockerImageVersionId":31011,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"papermill":{"default_parameters":{},"duration":7910.164883,"end_time":"2025-07-17T22:44:34.598864","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-07-17T20:32:44.433981","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}