{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1079953,"sourceType":"datasetVersion","datasetId":601280}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jobaerislam/lung-colon?scriptVersionId=251082820\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, random_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T22:59:15.559563Z","iopub.execute_input":"2025-07-17T22:59:15.560064Z","iopub.status.idle":"2025-07-17T22:59:15.567951Z","shell.execute_reply.started":"2025-07-17T22:59:15.56003Z","shell.execute_reply":"2025-07-17T22:59:15.566436Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"\n# ----- Step 1: Data Transform and Loading -----\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n])\n\n# Replace the path below with your dataset location if needed\nDATA_ROOT = '/kaggle/input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set'\nfull_dataset = datasets.ImageFolder(root=DATA_ROOT, transform=transform)\nprint(\"Classes:\", full_dataset.classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T22:59:15.569817Z","iopub.execute_input":"2025-07-17T22:59:15.570136Z","iopub.status.idle":"2025-07-17T22:59:30.349437Z","shell.execute_reply.started":"2025-07-17T22:59:15.570115Z","shell.execute_reply":"2025-07-17T22:59:30.34841Z"}},"outputs":[{"name":"stdout","text":"Classes: ['colon_image_sets', 'lung_image_sets']\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ----- Step 2: Dataset Split: 70/15/15 -----\ntotal_size = len(full_dataset)\ntrain_size = int(0.7 * total_size)\nval_size = int(0.15 * total_size)\ntest_size = total_size - train_size - val_size\n\ntrain_dataset, val_dataset, test_dataset = random_split(\n    full_dataset, [train_size, val_size, test_size],\n    generator=torch.Generator().manual_seed(42)\n)\n\nprint(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}, Test size: {len(test_dataset)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T22:59:30.351431Z","iopub.execute_input":"2025-07-17T22:59:30.351757Z","iopub.status.idle":"2025-07-17T22:59:30.361523Z","shell.execute_reply.started":"2025-07-17T22:59:30.351734Z","shell.execute_reply":"2025-07-17T22:59:30.360501Z"}},"outputs":[{"name":"stdout","text":"Train size: 17500, Val size: 3750, Test size: 3750\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ----- Step 3: Train dataset split for FL clients (3 clients) -----\nclient_split = [train_size // 3, train_size // 3, train_size - 2 * (train_size // 3)]\nclient_datasets = random_split(\n    train_dataset, client_split,\n    generator=torch.Generator().manual_seed(42)\n)\nclient_loaders = [DataLoader(ds, batch_size=16, shuffle=True, num_workers=2) for ds in client_datasets]\n\n# ----- Step 4: Val/Test Loaders -----\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T22:59:30.362521Z","iopub.execute_input":"2025-07-17T22:59:30.362834Z","iopub.status.idle":"2025-07-17T22:59:30.388423Z","shell.execute_reply.started":"2025-07-17T22:59:30.362812Z","shell.execute_reply":"2025-07-17T22:59:30.387329Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# ----- Step 5: Define MobileNetV2 model -----\ndef create_model():\n    model = models.mobilenet_v2(pretrained=True)\n    model.classifier[1] = nn.Linear(model.last_channel, 5)  # Adjust class count if needed\n    return model\n\n# ----- Step 6: Local training function -----\ndef train_local(model, dataloader, epochs=1, lr=1e-3, device='cpu'):\n    model.train()\n    model.to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    for epoch in range(epochs):\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n    return model.state_dict()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T22:59:30.390311Z","iopub.execute_input":"2025-07-17T22:59:30.390638Z","iopub.status.idle":"2025-07-17T22:59:30.408173Z","shell.execute_reply.started":"2025-07-17T22:59:30.390616Z","shell.execute_reply":"2025-07-17T22:59:30.407086Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# ----- Step 7: Federated averaging (FedAvg) -----\ndef average_weights(weights_list):\n    avg_weights = {}\n    for key in weights_list[0].keys():\n        avg_weights[key] = torch.stack([w[key].float() for w in weights_list], 0).mean(0)\n    return avg_weights\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T22:59:30.409534Z","iopub.execute_input":"2025-07-17T22:59:30.409899Z","iopub.status.idle":"2025-07-17T22:59:30.428272Z","shell.execute_reply.started":"2025-07-17T22:59:30.409869Z","shell.execute_reply":"2025-07-17T22:59:30.427021Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"\n# ----- Step 8: Evaluation function -----\ndef evaluate(model, dataloader, device='cpu'):\n    model.eval()\n    model.to(device)\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    return correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T22:59:30.429348Z","iopub.execute_input":"2025-07-17T22:59:30.429601Z","iopub.status.idle":"2025-07-17T22:59:30.454467Z","shell.execute_reply.started":"2025-07-17T22:59:30.429583Z","shell.execute_reply":"2025-07-17T22:59:30.453321Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"\n# ----- Step 9: Federated training loop -----\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\nglobal_model = create_model()\nglobal_model.to(device)\n\nNUM_ROUNDS = 5\nEPOCHS_PER_CLIENT = 1\n\nfor round_num in range(1, NUM_ROUNDS + 1):\n    print(f\"--- Round {round_num} ---\")\n    local_weights = []\n\n    for i, dataloader in enumerate(client_loaders):\n        print(f\"Training client {i+1} locally...\")\n        local_model = create_model()\n        local_model.load_state_dict(global_model.state_dict())\n        local_weights.append(\n            train_local(local_model, dataloader, epochs=EPOCHS_PER_CLIENT, device=device)\n        )\n\n    # Federated averaging of all client models\n    averaged_weights = average_weights(local_weights)\n    global_model.load_state_dict(averaged_weights)\n\n    # Evaluate on validation and test sets\n    val_acc = evaluate(global_model, val_loader, device=device)\n    test_acc = evaluate(global_model, test_loader, device=device)\n\n    print(f\"Round {round_num} completed.\")\n    print(f\"Validation Accuracy: {val_acc:.4f}\")\n    print(f\"Test Accuracy:       {test_acc:.4f}\\n\")\n\n# ----- Step 10: Save the global model -----\ntorch.save(global_model.state_dict(), 'federated_mobilenetv2.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T22:59:30.455596Z","iopub.execute_input":"2025-07-17T22:59:30.455863Z","iopub.status.idle":"2025-07-18T01:19:16.879496Z","shell.execute_reply.started":"2025-07-17T22:59:30.455844Z","shell.execute_reply":"2025-07-18T01:19:16.877742Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\n--- Round 1 ---\nTraining client 1 locally...\nTraining client 2 locally...\nTraining client 3 locally...\nRound 1 completed.\nValidation Accuracy: 0.9989\nTest Accuracy:       0.9995\n\n--- Round 2 ---\nTraining client 1 locally...\nTraining client 2 locally...\nTraining client 3 locally...\nRound 2 completed.\nValidation Accuracy: 1.0000\nTest Accuracy:       1.0000\n\n--- Round 3 ---\nTraining client 1 locally...\nTraining client 2 locally...\nTraining client 3 locally...\nRound 3 completed.\nValidation Accuracy: 0.9629\nTest Accuracy:       0.9629\n\n--- Round 4 ---\nTraining client 1 locally...\nTraining client 2 locally...\nTraining client 3 locally...\nRound 4 completed.\nValidation Accuracy: 0.9997\nTest Accuracy:       1.0000\n\n--- Round 5 ---\nTraining client 1 locally...\nTraining client 2 locally...\nTraining client 3 locally...\nRound 5 completed.\nValidation Accuracy: 1.0000\nTest Accuracy:       1.0000\n\n","output_type":"stream"}],"execution_count":16}]}